{
  "dashboard": {
    "title": "LLM Performance",
    "uid": "enterprise-agent-llm-performance",
    "version": 1,
    "timezone": "browser",
    "editable": true,
    "graphTooltip": 1,
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s",
    "tags": ["llm", "performance"],
    "templating": {
      "list": [
        {
          "name": "tenant_id",
          "type": "query",
          "label": "Tenant",
          "query": "label_values(llm_requests_total, tenant_id)",
          "datasource": {"type": "prometheus", "uid": "prometheus"},
          "allValue": ".*",
          "includeAll": true,
          "multi": false,
          "refresh": 2
        },
        {
          "name": "model",
          "type": "query",
          "label": "Model",
          "query": "label_values(llm_requests_total, model)",
          "datasource": {"type": "prometheus", "uid": "prometheus"},
          "allValue": ".*",
          "includeAll": true,
          "multi": true,
          "refresh": 2
        }
      ]
    },
    "panels": [
      {
        "id": 1,
        "title": "LLM Request Rate (req/s)",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m])",
            "legendFormat": "{{model}} — {{status}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "custom": {
              "lineWidth": 2,
              "fillOpacity": 10
            }
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom"}
        }
      },
      {
        "id": 2,
        "title": "LLM Error Rate (%)",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "100 * (rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\",status=\"error\"}[5m]) / rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m]))",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 1},
                {"color": "red", "value": 5}
              ]
            },
            "custom": {
              "lineWidth": 2,
              "fillOpacity": 10
            }
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom"}
        }
      },
      {
        "id": 3,
        "title": "LLM Request Latency — P50 / P95 / P99",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum by (le, model) (rate(llm_request_duration_seconds_bucket{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m])))",
            "legendFormat": "P50 {{model}}",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.95, sum by (le, model) (rate(llm_request_duration_seconds_bucket{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m])))",
            "legendFormat": "P95 {{model}}",
            "refId": "B"
          },
          {
            "expr": "histogram_quantile(0.99, sum by (le, model) (rate(llm_request_duration_seconds_bucket{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m])))",
            "legendFormat": "P99 {{model}}",
            "refId": "C"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "custom": {
              "lineWidth": 2,
              "fillOpacity": 5
            }
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom", "calcs": ["mean", "max", "lastNotNull"]}
        }
      },
      {
        "id": 4,
        "title": "Prompt Token Throughput (tokens/s)",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum by (model) (rate(llm_tokens_total{tenant_id=~\"$tenant_id\",model=~\"$model\",token_type=\"prompt\"}[5m]))",
            "legendFormat": "Prompt — {{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "custom": {"lineWidth": 2, "fillOpacity": 10}
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom"}
        }
      },
      {
        "id": 5,
        "title": "Completion Token Throughput (tokens/s)",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum by (model) (rate(llm_tokens_total{tenant_id=~\"$tenant_id\",model=~\"$model\",token_type=\"completion\"}[5m]))",
            "legendFormat": "Completion — {{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "custom": {"lineWidth": 2, "fillOpacity": 10}
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom"}
        }
      },
      {
        "id": 6,
        "title": "Cumulative Tokens by Model",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 24},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum by (model) (llm_tokens_total{tenant_id=~\"$tenant_id\",model=~\"$model\"})",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "custom": {"lineWidth": 2, "fillOpacity": 10}
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom"}
        }
      },
      {
        "id": 7,
        "title": "Model Distribution (requests, last 1 h)",
        "type": "piechart",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 24},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum by (model) (increase(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[1h]))",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "short"}
        },
        "options": {
          "pieType": "donut",
          "tooltip": {"mode": "single"},
          "legend": {"displayMode": "table", "placement": "right"}
        }
      },
      {
        "id": 8,
        "title": "LLM P95 Latency per Tenant",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 32},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum by (le, tenant_id) (rate(llm_request_duration_seconds_bucket{model=~\"$model\"}[5m])))",
            "legendFormat": "{{tenant_id}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "s",
            "custom": {"lineWidth": 2, "fillOpacity": 5}
          }
        },
        "options": {
          "tooltip": {"mode": "multi"},
          "legend": {"displayMode": "table", "placement": "bottom", "calcs": ["mean", "max"]}
        }
      },
      {
        "id": 9,
        "title": "Active LLM Requests (in-flight)",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 40},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum(rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[1m])) - sum(rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\",status!=\"pending\"}[1m]))",
            "legendFormat": "In-flight",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "short",
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"color": "green", "value": null},
                {"color": "yellow", "value": 50},
                {"color": "red", "value": 100}
              ]
            }
          }
        },
        "options": {
          "reduceOptions": {"calcs": ["lastNotNull"]},
          "colorMode": "background",
          "graphMode": "area"
        }
      },
      {
        "id": 10,
        "title": "Total LLM Requests (1 h)",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 40},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum(increase(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[1h]))",
            "legendFormat": "Total",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "short"}
        },
        "options": {
          "reduceOptions": {"calcs": ["lastNotNull"]},
          "colorMode": "value",
          "graphMode": "area"
        }
      },
      {
        "id": 11,
        "title": "Avg Prompt Tokens per Request",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 12, "y": 40},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum(rate(llm_tokens_total{tenant_id=~\"$tenant_id\",model=~\"$model\",token_type=\"prompt\"}[5m])) / sum(rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m]))",
            "legendFormat": "Avg Prompt Tokens",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "short"}
        },
        "options": {
          "reduceOptions": {"calcs": ["lastNotNull"]},
          "colorMode": "value",
          "graphMode": "none"
        }
      },
      {
        "id": 12,
        "title": "Avg Completion Tokens per Request",
        "type": "stat",
        "gridPos": {"h": 4, "w": 6, "x": 18, "y": 40},
        "datasource": {"type": "prometheus", "uid": "prometheus"},
        "targets": [
          {
            "expr": "sum(rate(llm_tokens_total{tenant_id=~\"$tenant_id\",model=~\"$model\",token_type=\"completion\"}[5m])) / sum(rate(llm_requests_total{tenant_id=~\"$tenant_id\",model=~\"$model\"}[5m]))",
            "legendFormat": "Avg Completion Tokens",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {"unit": "short"}
        },
        "options": {
          "reduceOptions": {"calcs": ["lastNotNull"]},
          "colorMode": "value",
          "graphMode": "none"
        }
      }
    ]
  }
}
